{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlbUHYok93TOBnJycfN3S0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UcwZEF6xuQiD"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"X5PXpEpcuVkZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CẤU TRÚC MÃ NGUỒN CỦA TÁC GIẢ\n","\n","THƯ MỤC:\n","* layer: cài đặt các tầng convolution, pooling, hàm kích hoạt dựa trên interface ở file layer.h.\n","\n","* third_party: chứa thư viện eigen hỗ trợ tính toán đại số.\n","\n","* loss: cài đặt hàm đo độ lỗi (cross entropy, mse).\n","\n","* optimizer: cài đặt stochastic gradient descent.\n","\n","TẬP TIN:\n","* mnist: đọc tập dữ liệu mnist. Dữ liệu sẽ được xử lý theo cột: mỗi cột sẽ tương ứng với một ảnh trắng đen (một kênh màu) gồm 28x28 dòng thể hiện cho mỗi pixel.\n","\n","* layer.h: cài đặt interface cho các tầng convolution, pooling.\n","\n","* network: cấu tạo của mô hình, chứa các layer và hoạt động của mỗi layer.\n","\n","* demo.cc: tập tin chính của chương trình, gồm cấu trúc và quá trình huấn luyện mô hình.\n","\n","MỘT VÀI BIẾN SỐ CỦA CHƯƠNG TRÌNH:\n","* channel: số kênh của dữ liệu. Nếu tầng convolution có channel_out=3 nghĩa là có 3 neuron (tương ứng 3 kernel) ở tầng này.\n","\n","* dim (với các tầng khác dense): số lượng pixel của ảnh, có giá trị bằng height x width x channel.\n","\n","* dim (với dense layer): số lượng neuron của tầng.\n","\n","* Quá trình nhân tích chập và pooling sẽ làm tròn phần tử lên với trường hợp dữ liệu có số lượng lẻ. Kết quả cuối cùng phụ thuộc vào nhiều yếu tố như stride, padding...\n","\n","\n","Dữ liệu bao gồm các ảnh trắng đen (có 1 kênh màu) được cấu trúc và xử lý theo ma trận cột, trong đó mỗi cột là một ảnh và 28x28 dòng cho mỗi pixel. Các tầng khác nhau có phương thức foward tương ứng với hành vi của tầng.\n"],"metadata":{"id":"jxR-VOX-upQl"}},{"cell_type":"markdown","source":["# THỰC HIỆN\n","Cần lưu ý ở file demo.cc trước khi chạy: dataset - model - epoch.\n","\n","Chỉnh sửa ở file demo.cc:\n","* Thêm thư viện time.h và 2 đối tượng time_t: start + end để đo thời gian train.\n","* Convolutional layer (Conv2D) có stride = 1, padding = 0.\n","* Pooling layer (MaxPooling2D) có stride = 2 (2x2)."],"metadata":{"id":"Pir219wbrnkJ"}},{"cell_type":"markdown","source":["# KẾ HOẠCH THỰC HIỆN\n","20-26/11: tìm hiểu về cnn, LeNet-5, setup và chạy mã nguồn mini-dnn-cpp với bộ dữ liệu mnist.\n","\n","27/11 - 03/12: tìm hiểu mã nguồn mini-dnn-cpp, thay đổi mô hình với cấu trúc LeNet-5 (được tinh chỉnh theo yêu cầu của đồ án) và chạy mô hình trên tập dữ liệu fashion MNIST.\n","\n","\n"],"metadata":{"id":"sV_k2p-lupXk"}},{"cell_type":"markdown","source":["# NGUỒN THAM KHẢO\n","BASE MODEL: mini-dnn-cpp\n","* https://github.com/iamhankai/mini-dnn-cpp.git\n","\n","DATASET: fashion MNIST\n","* https://github.com/zalandoresearch/fashion-mnist\n","\n","RELATED KNOWLEDGE: CNN + LeNet-5\n","* https://www.kaggle.com/code/blurredmachine/lenet-architecture-a-complete-guide/notebook\n","* https://setosa.io/ev/image-kernels/\n","* https://poloclub.github.io/cnn-explainer/\n","* https://www.tensorflow.org/\n","*\n"],"metadata":{"id":"rKCAsuFKupjk"}}]}